{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YoloSAM: Medical Scar Detection & Segmentation Tutorial\n",
    "\n",
    "Welcome to YoloSAM! This notebook will guide you through:\n",
    "- Installation and setup\n",
    "- Data preparation\n",
    "- Training YOLO and SAM models\n",
    "- Making predictions\n",
    "- Evaluating results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install YoloSAM\n",
    "!git clone https://github.com/Danialmoa/YoloSAM\n",
    "%cd YoloSAM\n",
    "!pip install -e . "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation\n",
    "Data should be in the following format:\n",
    "\n",
    "```\n",
    "data/\n",
    "├── train/\n",
    "│   ├── images/\n",
    "│   │   ├── image1.jpg\n",
    "│   │   ├── image2.jpg\n",
    "│   │   └── ...\n",
    "│   ├── masks/\n",
    "│   │   ├── image1.jpg\n",
    "│   │   ├── image2.jpg\n",
    "│   │   └── ...\n",
    "├── val/\n",
    "│   ├── images/\n",
    "│   │   ├── image1.jpg\n",
    "│   │   ├── image2.jpg\n",
    "│   │   └── ...\n",
    "│   ├── masks/\n",
    "│   │   ├── image1.jpg\n",
    "│   │   ├── image2.jpg\n",
    "│   │   └── ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finetune model\n",
    "# Training YOLO model (YOLO11n)\n",
    "\n",
    "# Convert masks to YOLO labels in the same folder structure.\n",
    "from utils.mask_to_yolo import MaskToYOLOConverter\n",
    "from utils.config import YOLOConfig\n",
    "from scripts.train_yolo import YOLOTrainer\n",
    "\n",
    "\n",
    "converter = MaskToYOLOConverter(class_id=0)  # 0 for 'scar' class\n",
    "\n",
    "# Convert your dataset in place\n",
    "converter.convert_dataset_inplace(\n",
    "    base_path='../sample_data',\n",
    "    min_area=5,  # Minimum area threshold (adjust as needed)\n",
    "    splits=['train', 'val']\n",
    ")\n",
    "\n",
    "config = YOLOConfig(\n",
    "    # Model settings\n",
    "    model_type=\"yolo11n\",\n",
    "    device=\"cpu\",\n",
    "    pretrained_path=\"../checkpoints\",\n",
    "    \n",
    "    # Dataset paths\n",
    "    dataset_path=\"../sample_data/train\",\n",
    "    val_dataset_path=\"../sample_data/val\",\n",
    "    class_names=['scar'],\n",
    "    \n",
    "    # Training parameters\n",
    "    epochs=10,\n",
    "    batch_size=16,\n",
    "    image_size=640,\n",
    "    patience=50,\n",
    "    \n",
    "    # Augmentation (optimized for medical scars)\n",
    "    mosaic=0.9,\n",
    "    mixup=0.1,\n",
    "    copy_paste=0.4,\n",
    "    degrees=15.0,\n",
    "    hsv_v=0.3,\n",
    "    \n",
    "    # Detection parameters\n",
    "    iou_threshold=0.2,\n",
    "    conf_threshold=0.15,\n",
    "    max_detections=2,\n",
    "    \n",
    "    # Project settings\n",
    "    project_name=\"yolo_scar_detection\",\n",
    "    experiment_name=\"enhanced_scar_detection\",\n",
    "    \n",
    "    # Wandb settings\n",
    "    wandb_project=\"YOLO-scar-detection\",\n",
    "    wandb_name=\"scar_detection_v1\",\n",
    "    wandb_mode=\"disabled\"  # Set to \"online\" to enable wandb logging\n",
    ")\n",
    "    \n",
    "# Create trainer\n",
    "trainer = YOLOTrainer(config)\n",
    "\n",
    "# Train the model\n",
    "results = trainer.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FineTune SAM model \n",
    "Two ways to finetune SAM model\n",
    "\n",
    "1. Using Yolo prompt\n",
    "2. Using ground truth mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FineTune SAM model With Yolo prompt\n",
    "\n",
    "from scripts.train_sam import TrainSAM\n",
    "from utils.dataset import SAMDataset\n",
    "from utils.config import SAMFinetuneConfig, SAMDatasetConfig\n",
    "\n",
    "finetune_config = SAMFinetuneConfig(\n",
    "        device='cpu',\n",
    "        wandb_project='SAM_finetune',\n",
    "        wandb_name='test_run',\n",
    "        model_type='vit_b',\n",
    "        sam_path='../checkpoints/sam_vit_b_01ec64.pth',\n",
    "        num_epochs=1,\n",
    "        batch_size=2,\n",
    "        learning_rate=1e-5,\n",
    "        weight_decay=1e-4,\n",
    "        lambda_bce=0.2, \n",
    "        lambda_kl=0.2,\n",
    "        sigma=1,\n",
    "        wandb_mode='disabled',\n",
    "        num_workers=0\n",
    "    )\n",
    "\n",
    "train_dataset_config = SAMDatasetConfig(\n",
    "    dataset_path='../sample_data/train/',\n",
    "    remove_nonscar=True,\n",
    "    sample_size=2,\n",
    "    point_prompt=False, # -> If True, Random generation of points base on the mask\n",
    "    box_prompt=False, # -> If True, box prompt is generated based on the mask\n",
    "    enable_direction_aug=False, # -> If True, direction augmentation is enabled\n",
    "    enable_size_aug=False, # -> If True, size augmentation is enabled\n",
    "    yolo_prompt=True, # -> If True, yolo prompt is generated based on the mask\n",
    "    yolo_model_path='../checkpoints/yolo11n.pt', # -> Path to the yolo model\n",
    "    yolo_conf_threshold=0.25, # -> Confidence threshold for yolo\n",
    "    yolo_iou_threshold=0.45, # -> IoU threshold for yolo\n",
    "    yolo_imgsz=640, # -> Image size for yolo\n",
    "    image_size=1024, \n",
    "    train=True\n",
    ")\n",
    "\n",
    "val_dataset_config = SAMDatasetConfig(\n",
    "    dataset_path='../sample_data/val/',\n",
    "    remove_nonscar=True,\n",
    "    sample_size=2,\n",
    "    point_prompt=False,\n",
    "    box_prompt=False,\n",
    "    yolo_prompt=True,\n",
    "    yolo_model_path='../checkpoints/yolo11n.pt',\n",
    "    yolo_conf_threshold=0.25,\n",
    "    yolo_iou_threshold=0.45,\n",
    "    yolo_imgsz=640,\n",
    "    image_size=1024,\n",
    "    train=False\n",
    ")\n",
    "\n",
    "train_dataset = SAMDataset(train_dataset_config)\n",
    "val_dataset = SAMDataset(val_dataset_config)\n",
    "\n",
    "trainer = TrainSAM(finetune_config, train_dataset, val_dataset)\n",
    "trainer.train(finetune_config.num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FineTune SAM model with ground truth mask\n",
    "\n",
    "from scripts.train_sam import TrainSAM\n",
    "from utils.dataset import SAMDataset\n",
    "from utils.config import SAMFinetuneConfig, SAMDatasetConfig\n",
    "\n",
    "finetune_config = SAMFinetuneConfig(\n",
    "        device='cpu',\n",
    "        wandb_project='SAM_finetune',\n",
    "        wandb_name='test_run',\n",
    "        model_type='vit_b',\n",
    "        sam_path='../checkpoints/sam_vit_b_01ec64.pth',\n",
    "        num_epochs=1,\n",
    "        batch_size=2,\n",
    "        learning_rate=1e-5,\n",
    "        weight_decay=1e-4,\n",
    "        lambda_bce=0.2, \n",
    "        lambda_kl=0.2,\n",
    "        sigma=1,\n",
    "        wandb_mode='disabled',\n",
    "        num_workers=0\n",
    "    )\n",
    "\n",
    "train_dataset_config = SAMDatasetConfig(\n",
    "    dataset_path='../sample_data/train/',\n",
    "    remove_nonscar=True, # -> If True, remove non-scar images\n",
    "    sample_size=2,\n",
    "    point_prompt=True, # -> If True, Random generation of points base on the mask\n",
    "    point_prompt_types=['positive'], # -> Types of points to generate (Negative, Positive)\n",
    "    num_points=3, # -> Number of points to generate\n",
    "    box_prompt=True, # -> If True, box prompt is generated based on the mask\n",
    "    enable_direction_aug=True, # -> If True, direction augmentation is enabled\n",
    "    enable_size_aug=True, # -> If True, size augmentation is enabled\n",
    "    yolo_prompt=False, # -> If True, yolo prompt is generated based on the mask\n",
    "    image_size=1024, \n",
    "    train=True\n",
    ")\n",
    "\n",
    "val_dataset_config = SAMDatasetConfig(\n",
    "    dataset_path='../sample_data/val/',\n",
    "    remove_nonscar=True,\n",
    "    sample_size=2,\n",
    "    point_prompt=True,\n",
    "    point_prompt_types=['positive'],\n",
    "    num_points=3,\n",
    "    box_prompt=True,\n",
    "    enable_direction_aug=False,\n",
    "    enable_size_aug=False,\n",
    "    image_size=1024,\n",
    "    train=False\n",
    ")\n",
    "\n",
    "train_dataset = SAMDataset(train_dataset_config)\n",
    "val_dataset = SAMDataset(val_dataset_config)\n",
    "\n",
    "trainer = TrainSAM(finetune_config, train_dataset, val_dataset)\n",
    "trainer.train(finetune_config.num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.inference import YoloSAMInference\n",
    "from utils.config import YoloSAMInferenceConfig\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "config = YoloSAMInferenceConfig(\n",
    "    yolo_checkpoint_path=\"../runs/yolo_scar_detection2/weights/best.pt\",\n",
    "    sam_checkpoint_path=\"../checkpoints/sam_vit_b_01ec64.pth\",\n",
    "    device=\"cpu\"\n",
    ")\n",
    "\n",
    "inference_pipeline = YoloSAMInference(config=config)\n",
    "\n",
    "image_path = \"../sample_data/val/images/Case_P004_slice_01.png\"\n",
    "\n",
    "results = inference_pipeline.predict(image_path)\n",
    "output_image = inference_pipeline.visualize_results(results)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.imshow(output_image)\n",
    "plt.title(\"YoloSAM Inference Results\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
